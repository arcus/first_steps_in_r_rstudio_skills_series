---
format: 
  revealjs:
    theme: [serif, custom.scss]
    scrollable: true
    logo: media/chop_arcus_initiative_logo.png
    footer: Arcus Education, Children's Hospital of Philadelphia 
    css: styles.css
---
## Welcome {.smaller}

These slides available at: <https://arcus.github.io/first_steps_in_r_rstudio_skills_series/session_2.html>

-   Use keyboard arrow keys to
    -   advance ( → ) and
    -   go back ( ← )
-   Type "s" to see speaker notes
-   Type "?" to see other keyboard shortcuts

```{r echo = FALSE}
library(countdown)
```


::: notes
As we prepare to get started, I'd like to encourage you to open these slides on your own browser, so you will have them available to refer to later. There are also a number of links you may want to click on. I'll copy paste that URL, where the slide deck is located, into chat, so everyone has it.

This first slide is just to help you navigate this slide deck if you look at these slides on your own! And yes, there are ample speaker notes, so if you missed something I said, chances are it's going to be in the speaker notes of the slide.
:::

## About Arcus / Your Presenter {.smaller}

::::: {.columns .v-center-container}
::: {.column .small-text width="60%"}
Arcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility.

-   Arcus app: <https://arcus.chop.edu>
-   Arcus Sharepoint site: <https://chop365.sharepoint.com/sites/Arcus>

Among the many teams in Arcus, I represent Arcus Education!

![](media/arcus_website.png){.two-thirds .bordered fig-alt="Arcus website which displays tools and services including cohort discovery, arcus archives, data catalog, education and training, scientific projects, and clinical data query."}
:::

::: {.column .small-text width="40%"}
![](media/arcus_research_data_lifecycle.png){fig-alt="A circular diagram showing five project phases, including Discover: explore available data, Plan: plan your research project, Collect: receive your data, Analyze: analyze data in an Arcus lab, and Share: contribute data to archives."}
:::
:::::

::: notes

Thanks again for joining us, and welcome to our session today! My name is ______ [add pronouns here if you want], and I'll be leading today's session.

I've already talked a bit about Arcus in the first session of this Skills Series, so I'll just skip most of that this time and simply say that Arcus is an initiative by the Research Institute aimed at promoting data discovery and reuse and increasing research reproducibility.

You can find out more by checking out these links.

And finally, a little more about me: I work in Arcus Education.  Our role is to support CHOP scientists by helping researchers acquire data science skills.  That's why we have Skills Series like this one!

:::
## Arcus Education

::::: {.columns .v-center-container}
::: {.column .small-text width="50%"}
![](media/arcus_education_page.png){.bordered fig-alt="Education website page that includes three sections titled Getting Started with Arcus, Learn Data Science Skills, and Curate Your Own Learning Experience."}
:::

::: {.column .small-text width="50%"}
Arcus education provides data science training to researchers ...

(and often this is useful to non-researchers too!).

<https://arcus.chop.edu/i-want-to/arcus-education>

Email us! [arcus-education\@chop.edu](mailto:arcus-education@chop.edu){.email}
:::
:::::

::: notes
The Arcus Education team does lots of different kinds of education. Again, we talked about this in our first session, so I'm going to skip most of this.

Please check out that education page that is linked here to find out more about some of our services. You can also email us at arcus dash education at chop dot edu.
:::


## First Steps in R and RStudio {.smaller}

Arcus Education provides "Skills Series" for the entire CHOP community.

This Skills Series is a 5-session series aimed at helping you take your first steps in R and RStudio!

-   Session 1: Review and Setup
-   Session 2: Projects and File Ingestion
-   Session 3: Exploring Data Visually, Using ggplot2
-   Session 4: Selecting Data Using dplyr
-   Session 5: Putting it All Together: Communicating

::: notes
Just a reminder about what you're in today.

In this series, we're going to take five sessions to help you make your first steps in R and RStudio. If you've never coded in R or used the RStudio software, and you want some support to get started, this is a great workshop series for you.

After you finish these five sessions, you'll have a little experience with R and RStudio.  The goal is to help you feel more confident and have enough experience to be able to keep learning specialized skills titrated to your needs.  If we were to compare learning R to learning to drive, this series is the equivalent of having you drive around a parking lot, under supervision, in a controlled situation.
:::

## Session 2 Itinerary {.smaller}

Projects and File Ingestion

  * File systems can be challenging to navigate
  * Projects in RStudio
  * Installing and loading packages
  * Tabular data ingestion from .csv files
  * Functions in R

Goals:

- Create project and install package (unless you did Session 1)
- Be able to explain when to use `install.packages()` and when to use `library()`
- Ingest data from a .csv and look at it

::: notes
So let's get started with this second session. In this session we're going to hit the ground running.  You need to already have a Posit.cloud account, so if you don't have that, it is absolutely critical that you pay attention in the next slide.

We're going to have you go into your Posit account and start a new project.  We'll explain why projects are so useful, and go over installing and loading packages, ingesting data, and functions in R.

Here are our goals.  By the end of today I want you to be able to create a project and install a package (which may already be something you did last time).  I want you to be able to explain when you'll use install dot packages and when you'll use library, and I want you to be able to ingest data from a .csv file and examine that data in RStudio.
:::

## Posit.Cloud (for learning) {.smaller}

[https://posit.cloud](https://posit.cloud) is a great place for learning or practice with public (NOT CHOP!) datasets.

Please open your First Steps in R and RStudio Exercises project in Posit.cloud now.

If you did not already set up a Posit.cloud account with the exercise files in the first session of this Series, please do the following, now:

* Make sure you have a Cloud Free tier account at [https://posit.cloud](https://posit.cloud).  See [last session's slides](https://arcus.github.io/first_steps_in_r_rstudio_skills_series/session_1.html#/posit.cloud-for-learning-only) for help.
* [Create a new project that clones our exercise files.](https://arcus.github.io/first_steps_in_r_rstudio_skills_series/session_1.html#/creating-a-project-in-posit)

```{r echo=FALSE}
countdown(minutes = 2, seconds = 0)
```

::: notes
Posit.cloud is an online, cloud based service provided by Posit, the company that makes the RStudio software.  It's easy reliable for learners.  As teachers, we can concentrate on our learners really acquiring the skills around R and RStudio, without being bogged down by weird individual installation differences from computer to computer.

Using Posit.cloud is a requirement for your continued participation in this workshop, because we can't help you troubleshoot details of your particular computer and its installation details. If you set things up in the first session of the Series, please log in to Posit.cloud and open the project with the Skills Series exercise files.  If you didn't set things up yet, please do that now.  I'll copy and paste those two bullet points into chat so you have those. [Do it].

Let's take just a few minutes to make sure we're all set up.  I'll give folks a few minutes to do that!
:::

## Updating From Git {.smaller}

- I might update the exercise files!
- This means you should save anything you will make changes to with a **new name** (like `session_2_exercise_janedoe.qmd`)
- Then if I update `session_2_exercise.qmd` you can get the new version and not mess up your "janedoe" version
- Go to Git and choose "Pull Branches" to get any updates

![](media/pull_branches.png){.bordered fig-alt="git menu with pull branches indicated"}

::: notes

OK, so let's talk about keeping your exercise files fresh.

It's possible, as we go through this series, that I realize I want to make improvements or fixes to the exercise files, and if I do that, I want you to get the up to date changes.

Because I might make changes, it's important that you not make your own changes to the same files with the same names, because our changes might be in conflict.  So when you work in the exercise files, you'll see the instruction to save the file with your initials at the end.  Please make sure to do that before you do anything else!

And now I'll demo how to do this in my own Posit.cloud account.  I have my Posit.cloud account open, and in my case, I don't have any files open.  You might have something open from the last time you worked here, so when you click on the Git button, you might see some menu options that have to do with that particular file.  You can ignore those menu options.  What I want you to do is look for Pull branches.  Click there.

:::

## Where are your files? {.smaller}

- Knowing where your files are can be tricky
- RStudio / Posit.cloud "Projects" can help
- Projects are directories that hold analysis scripts, data, and project info close together

::: {.columns .v-center-container}
::: {.column .small-text width="60%"}
In Posit.cloud, "New Project" is a big blue button:
![](media/posit_cloud_new_project.png){.bordered fig-alt="Posit.cloud workspace with the New Project button indicated."}
:::
::: {.column .small-text width="40%"}

In RStudio Desktop on your computer, you have to go to the File menu and choose "New Project":
![](media/rstudio_desktop_new_project.png){.bordered fig-alt="RStudio Desktop menu on a Mac, showing File menu with New Project option indicated."}

:::
:::

::: notes
OK, before we get started working with our exercise files, let's talk about some common struggles. One of the biggest challenges some people have, especially if they've never worked in the command line, is finding their own files. They know they downloaded it, or they double clicked on a .csv file attachment in Outlook and they're not sure where that file lives. 

Working in Projects is a great way to help keep your data really close to your analysis scripts, so it's a lot easier to find your data.  Projects are directories that RStudio creates in which your data and your analysis, as well as some information about your project, are all stored together in a single folder.  And you can have 2, or three, or a dozen different Projects, all kept separate from each other, to keep from mixing up your files. 

In Posit.cloud, Projects are the way you **have** to organize your work, so it's really easy to use Projects there.  On your own computer, you're not forced to use Projects, but you **should** use them.  If you're working in your own computer, you have to have the discipline to not just make new R scripts right away, but rather, first make a new Project to hold related files together, and then within that project make your analysis scripts.

:::



## Advantages to using Projects {.smaller}

-   Keeping track of your files gets easier
-   Projects allow you to keep your various efforts separated (wait, which "my_data" is this?)
-   Multiple sessions of RStudio open on your computer that don't interfere with each other.

::: notes
Let's sum up the major advantages of using Projects.

If you're like me, you might work on several different analysis projects at a time. And if you just have one RStudio window open, which means one R session, you can accidentally trip over yourself. Let's say you have two different R scripts, each of which creates the object `my_data`, or `cleaned_data`, or a similar kind of generic name.  Maybe you're doing work for two different research projects.  What happens when you go back and forth between these files? You end up clobbering yourself and saving the audiology data in the onco project or something like that.

It's much cleaner and safer to work using Projects, in which all the related analysis and data files for a given effort are stored in the same directory. RStudio can also dedicate a session per project if you want to have several projects open at a time.  For example, on my computer, I might have two or three copies of RStudio open at a time, each one in a separate Project, and each one is completely isolated from the other.  I can go back and forth and I can have an onco dataset I call "my_data" and an audiology dataset I call "my_data", and RStudio will keep them totally separate, because they're in different Projects.
:::

## Importing Data {.smaller}

* Importing / Ingesting data is the first step to analyzing it!
* You can use "base R" (the factory settings) to ingest data
* But we suggest using an add-on package called `tidyverse` instead.

::: notes
Great, so you have a Project in Posit.cloud.  And among the files in that project, we've supplied you with some data, some real research data that's publicly available, to get you started.  The first step in the data analysis pipeline is to bring in, or import, or ingest, these are all synonyms that mean the same thing, the data into your R session. 

Base R is the language by itself, and base R has some data ingestion tools, but we like some of the packages that have been built to enrich R and make it better.  We really like tidyverse, and this is what lots of people use today in R to work with tabular data, with data that comes in rows and columns.  So we're going to use tidyverse to ingest data and work with data in this series of workshops.
:::

## Lots of Ways to Ingest Data {.smaller}

Data can be ingested into R from lots of sources:

* SQL Databases
* REDCap
* API Endpoints (Census Bureau, NYT, PubMed)
* Data exported from SAS / SPSS / Stata
* .json, .csv, .xlsx, .tsv, .txt, .arff files 
* and much much more!

::: notes

You can bring data into R from lots of different kinds of sources, as you can see on this slide.  But I want to concentrate on the one of the most portable and popular data types you'll be seeing frequently, and that's the .CSV file.  Please don't think that R is limited to .csv data, it certainly is not.  But that's what we'll be doing in our workshop series here.  
:::

## CSV {.smaller}


::: columns
::: {.column width="35%"}
We're supplying you with .csv data.
::: 

::: {.column width="56%"}
![](media/csv.png){fig-alt="A text file with many numeric and text values separated by commas, with no spaces between the fields, and each row being a new data entry." }
::: 
::: 

::: notes
We're giving you some CSV data.  CSV stands for **comma-separated values**. 

A .csv file is a plain text file, which means you can open it in a text editor and look at it. Now, this isn't how we normally open CSVs.  Usually we open them **not** in a text editor, but rather in  Microsoft Excel or another spreadsheet program. In case you've never seen the plain text version of a CSV, here is an example of what raw csv data looks like when we open it in a text editor.  See how it's literally made up of values, separated by commas?  That's why it's a comma separated values file!

Here we have a screenshot of a .csv file with human subject IDs, information about the intervention they received, and some clinical information about them like whether they have ascites or edema and measures like their cholesterol and platelet count.

This data structure is called **rectangular** or **"tabular"** because it falls into rows and columns, often called a table, where each row has the same number of columns, and each columns has the same number of rows.

Also note that this particular .csv file has a **header** row that instead of data, has a name for each column. .csv files often have such a header row and unless we specify otherwise, when we import this data, R assumes the first line is a header row. Not all .csv files have headers, however, so be aware that you might run across these at some point.
:::

## Tidyverse {.smaller}

::: columns
::: {.column width="70%"}
-   A consistent way to organize data
-   Human readable, concise, consistent code
-   Build pipelines from atomic data analysis steps
:::

::: {.column width="30%"}
![](media/tidyverse_logo.png){fig-alt="Tidyverse logo."}
:::
:::::

::: notes
To import our CSV data, we need some additional data analysis tools. In this course, we will be leveraging the Tidyverse.

The Tidyverse is a set of tools that a lot of people use for working with rectangular, or tabular data, the kind of data that comes with rows and columns. Many people, myself included, think that using the tidyverse is the best way to work with tabular data.

We won't explain what tidy data is right now, but the idea of working in a tidy way with tidy data is obviously very central to this group of tools!

The tidyverse tries to provide a consistent way to work with data that has clean, easy to read code.  And one of the most important things it can provide is the ability to make pipelines that connect small data analysis steps together.  We'll talk about all of this in the next few weeks.

:::

## Installing a Package {.smaller}

::: columns
::: {.column width="50%"}
(You probably did this already!)

* Look in "Files" tab.  
* Go into the "solutions" folder 
* Click on "setup.qmd".  
* Run the only code chunk there (green triangle "play" button)

:::
::: {.column .small-text width="50%"}
![](media/run_setup_chunk.png){.bordered fig-alt="setup.qmd script with the code chunk indicated, an arrow pointing to the execute code chunk button."}
:::
:::
```{r echo=FALSE}
countdown(minutes = 1, seconds = 0)
```

::: notes
If you were in our first session, you probably already installed tidyverse, and you don't need to do this.  You're welcome to do it again if you like.  But in case something went wrong last time, or you couldn't make it, I wanted to include this slide today. 

In the lower right pane of your project, you should see a "Files" tab.  Go into the "solutions" folder there and click on "setup.qmd".  That will open up **our** version of the setup document.  If you made your own setup file in the exercises folder, your version might will look a little different than the one we built, and that's okay.

Go ahead and open that file and run the only cell there, by clicking the green play button in the code cell, the green triangle button.

You will get a lot of output in your console window if you're installing this for the first time, and that's usually just fine. I'll give you a minute to do this.

I'll also say that this is the last time we'll pause to do the setup.  After this, I'm going to assume that in sessions 3, 4, and 5, everyone is ready to go, and I won't slow down to make sure people have Posit.cloud set up and ready to go.  
:::

## Installing and Loading Packages

::: columns
::: {.column .small-text width="50%"}
![](media/package.png){.half fig-alt="The word tidyverse followed by the depiction of a package containing 3 help files, 3 data sets, and 4 functions."}
:::

::: {.column .small-text width="50%"}
`install.packages("tidyverse")` downloads the package (do once)



`library(tidyverse)` loads the package (do once per session)
:::
:::

::: notes
The **tidyverse** is package.  A package is a collection of functions, sometimes some data, and often some really useful help documentation that we can use to extend the basic R language, also known as "base R". Tidyverse is kind of a special package because it in fact contains multiple other packages that work together to do a number of tasks related to importing, reshaping, visualizing, and analyzing data.  It's a package of packages.

You can download and **install** a package with the command `install.packages`. For example, to install the tidyverse package, you would use `install.packages("tidyverse")`. Each package you want to use needs to be installed only once on each computer or each Posit.cloud project for any given version of that package.

Make sure you **include the quotes** around package names when you use `install.packages`. Learning when to use quotes is kind of a trial and error thing in R, but you should use it here.

After you've installed the package, in order to use the functions that it provides, you also need to tell R to **load** the package into memory. This is done with the command `library`. And you want to use `library` every single time you start a new R session, and usually we do that by adding the library command to the top of any script we write that will use that package.  We're going to talk about a function in the next couple of slides that comes from the tidyverse, for example.  To use that function, we have to use `library(tidyverse)` to make sure we have access to it.
:::

## read_csv() {.smaller}

`data_frame <- read_csv(file_name)`

* `read_csv` ingests a **file**, creating an **object** that exists in your R **environment**
* You have to ingest (import, bring in, other synonym...) data into the R environment to work with it

![](media/csv_import.png){.half fig-align="center" fig-alt="A depiction of a CSV file being transformed into rows and columns of data."}

::: notes
We can ingest or import CSV files using the `read_csv()` function.

We use `read_csv` and other data ingestion functions to bring data into our R environment, because we have to bring data into R to be able to work with the data.

Let's go over this `read_csv` function, which reads a CSV file into  what we call a data frame object. 

A data frame is a type of object in R that holds tabular data. "Tabular" is just a word that means "table shaped", with rows and columns.
:::

## Functions {.smaller}

`data_frame <- read_csv(file_name)`

* `read_csv` is the **function** name

::: notes
Now is a good moment to explain **functions** in the context of programming languages like R.

`read_csv()` is a **function**. Functions are defined in base R and also in packages. In our case, read_csv belongs to a package called "readr", which the one of the packages that is included in the tidyverse suite of packages.  In our case, let's say we've already installed and loaded tidyverse.  That means we can use read_csv.

You may be familiar with functions from math class. A function takes an input, say an 'x' value, and returns an output, say a 'y' value. Functions in computer programming also take inputs and return outputs. 

For the `read_csv` function, the input is the file name of a CSV file; and the output is a data frame, a new object created in your R environment, which contains the contents of that .csv file.
:::

## Functions {.smaller}

`data_frame <- read_csv(file_name)`

* `read_csv` is the **function** name
* `file_name` is an **argument** passed to the function.

::: notes
In the snippet of code that reads in a csv to create a data frame, we have a **function** with an **argument** that creates an **object**.

The input that goes into a function is called an **argument**. The argument to a function gets put in parentheses.

A function can have zero, one, or many arguments. If there is more than one argument, we use commas to separate them.
:::

## Functions {.smaller}

`data_frame <- read_csv(file_name)`

* `read_csv` is the **function** name
* `file_name` is an **argument** passed to the function.
* `data_frame` is a named **object** that will receive the **output** of the function.

::: notes
The output of the `read_csv` function is a data frame object. You want to store that data inside of a named object so you can use it in R later for other things. For example, after you read in your csv, you might want to summarize or visualize your data.  

I can choose to name this data frame what I want, but there are some good standards for how to name things that you'll read about in today's exercise files.  I could read in data and just call it "my_data", but it's probably better to call it "flu_trends" or some other descriptive name.
:::

## Functions {.smaller}

`data_frame <- read_csv(file_name)`

* `read_csv` is the **function** name
* `file_name` is an **argument** passed to the function.
* `data_frame` is a named **object** that will receive the **output** of the function.
* `<-` is the **assignment operator** that makes what's on the right be assigned to the named object on the right

::: notes
To put the output of the `read_csv` function into a named object, we use the **assignment operator**.

The assignment operator is a less than symbol followed by a dash and resembles an arrow pointing left. 
:::

## Hands-on {.smaller}

::::: {.columns .v-center-container}
::: {.column .small-text width="50%"}
![](media/exercises_folder.png){.bordered fig-alt="File browser with exercises folder indicated."}
![](media/session_2_exercise.png){.bordered fig-alt="Exercises folder with session_2_exercise.qmd file indicated."}
:::
::: {.column .small-text width="50%"}

* Go into your First Steps in R and RStudio Exercises project in Posit.cloud
* Go into the File tab in the lower right pane
* Find the "Exercises" folder
* Click on "session_2_exercise.qmd".
* Read through that file and complete the exercises!
* We'll give you a few minutes to complete this.
:::

:::

```{r echo = FALSE}
countdown(minutes = 12, seconds = 0)
```

::: notes

Okay, so I want you to spend a big chunk of your time today doing hands-on work.  So what you're going to do is open your Posit.cloud project with the First steps in R and RStudio exercises, and then in the file browser, go to the exercises folder and find session_2_exercise and open it.  Then just read that file and do what it says!

I'll start the timer here.   (You should be around minute 25-30 at this point.  You can adjust as needed)

----- when time is up ----

OK, so you may not be finished, but I want to demo this, in case anyone had issues.  If you did have problems, there is a solutions folder, and you can navigate there by clicking on the File tab in the lower right pane, then "project" in the bread crumbs at the top grey bar of the file navigator, then in the file browser you should see "solutions".  Click there, and then you'll see solutions for each session.

But let's go through this together.  I'm going to open the exercise file and go through it.

[Go through each thing... it should be pretty straightforward... but leave 5 minutes for the poll / Q&A at least]


:::


## Bonus Content: File Paths -- the "where" {.smaller}

-   A few tips:
    -   `/` means "go into a child directory" (`\` in Windows)
    -   `/` as the first symbol means "start at the root"
    -   `.` means "this directory"
    -   `..` means "the parent directory of this directory"
    -   `~` means "my home directory"
-   Relative path -- "directions from here"
-   Absolute path -- "directions from anywhere"
-   Working directory -- R's "starting place"

[Great module on Directories and File Paths](https://liascript.github.io/course/?https://raw.githubusercontent.com/arcus/education_modules/main/directories_and_file_paths/directories_and_file_paths.md#1)

::: notes

[This is bonus content, that I have sort if in my back pocket in case we have time to cover it... choose one option below...]

Option 1: I won't go over this slide, but if understanding file paths is interesting to you, there's a great link there for you to learn more.

Option 2: Read below.

If you have already worked in the command line, you might not have any problem finding files on your computer, but some of you might find it tricky.  

We're going to offer a brief handful of tips for understanding file paths, and this is true for all files, not just related to R or data analysis. 

First off, Windows is a weird operating system and is unlike the rest of the world's major operating systems, like Unix, Linux, and MacOS, in how it does file paths. Most file paths use forward slashes, not backward slashes.  A slash means you're going into a new subdirectory or subfolder.

And a few other special symbols are useful to know. A single dot means "this directory", two dots means "go into the directory that holds the one I'm in now", and a tilde means "my home directory", which will differ from user to user on a shared system like a server. 

In your analysis scripts, you'll often have to decide if you want to use what's called a "relative path" or an "absolute path" to tell R where a file is. There are advantages and disadvantages to both, but if we're using Projects, we can usually use relative paths more easily.

A relative path assumes that we're starting in the same place and have common knowledge. So if I was at home, describing where my keyboard is, I'd say "go upstairs to the second floor, and then on the street side of the house, there's my office. Then go inside and you'll find the keyboard on my desk."  That makes sense if you're also inside my house.

But if you're NOT in my house, you're in your house, which doesn't have a second floor, you would say, "hey, your directions to go to the second floor don't make sense.  Path not found." A relative path doesn't work when we're not starting in the same place. 

And that brings us to the idea of a working directory. Any time you are working in R, it's running with a starting point, its working directory. The great thing about RStudio is that it does a good job of guessing what you want the working directory to be, based on the file you're working on.  Everyone has the same starting point, so to speak.

An absolute path is a path that includes enough detail so that the location is clear from anywhere in the computer. For example, in the physical world, an absolute path would be if I said, "go to 123 Main Street, Philadelphia, go inside, go to the second floor, go to the street side, open the door, go inside, and look on the desk. The keyboard is there."  Now, the benefit is that it's very precise.  But the downside is that it's lengthy and annoying to construct sometimes, and if you move the whole folder of your project, you've changed addresses, essentially, and messed things up.

If you want to learn more, we've created a module all about file paths that you might find useful, so check that out if you're interested!
:::

## Recap {.smaller}

* Functions (argument, input, output, objects)
* Working with code chunks
* Ingesting data from a .csv
* Working with the environment pane
* Learning about help in R
* Naming things
* Rendering

::: notes

You did a lot today, so give one another a heart emoji or thumbs up in the reactions.  We covered functions and data ingestion, and you did so much additional hands on work, including working with the environment pane, the help pane, rendering a quarto document, working with code chunks... it was a lot!  If you want, drop a word or phrase into chat to tell us about how you're feeling at the close of the hour.

:::

## Q&A / Was This Effective? {.smaller}

In our team, we like to measure our effectiveness.

Goals:

- Create project and install package (unless you did Session 1)
- Be able to explain when to use `install.packages()` and when to use `library()`
- Ingest data from a .csv and look at it


::: notes

Now, this is not the final slide, but we're a group that likes to measure our effectiveness and make changes based on what we learn.  So before we do questions and answers, we like to make sure to give our learners a poll to see if we made a good use of your time.  We're going to ask if we were effective in reaching our goals today, and those goals are on the screen in order to help you answer that question.  Once you answer that poll, feel free to type a question into chat.
:::

## Next Session

Exploring Data Visually, Using ggplot2

  * ggplot2 syntax
  * Mapping Aesthetics 
  * Setting Visuals
  * Color Palettes
  
::: notes

In our next session, we're going to do my favorite session, data visualization.  If you have an artistic streak, I think you'll really enjoy this session.  We'll talk about the grammar of graphics, using the library ggplot2, which is part of the tidyverse.  We'll talk about the very important distinction between mapping aesthetics and setting visual properties, and we'll touch on some color palette possibilities.  It's going to be very hands-on with none of the posit.cloud setup next time, so please make sure you're all set up and ready to go for session 3.  Thanks again for all your hard work and we'll see you next time!
:::

